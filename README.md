## Chaine de streaming avec des containers Dockers/Kafka, Airflow\...pour l‚Äôanalyse des param√®tres vitaux des patients

Mettre en place une configuration de streaming afin de traiter des donn√©es re√ßues en continu en utilisant Docker, Kafka, Airflow\...

## Description de la Chaine de streaming : Solution ETL pour l‚Äôanalyse des param√®tres vitaux des patients

Dans le cadre de la mise en place d‚Äôune cha√Æne de streaming avec des containers Dockers/Kafka et Airflow, nous avons √©labor√© une solution ETL pour l‚Äôanalyse des param√®tres vitaux des patients.

En effet, la surveillance continue des patients et l'analyse en temps r√©el de leurs donn√©es vitales sont devenues des imp√©ratifs. Les √©tablissements de sant√© sont confront√©s √† un volume croissant de donn√©es provenant de dispositifs m√©dicaux connect√©s, de capteurs portables et de syst√®mes d'information hospitaliers. Pour transformer ces donn√©es brutes en informations exploitables et am√©liorer la prise de d√©cision clinique, une infrastructure de traitement de donn√©es robuste et √©volutive est indispensable.

## Architecture r√©alis√©e pour notre solution

Le pipeline de traitement s'ex√©cute **toutes les 5 minutes** et comprend les √©tapes suivantes :

1. **G√©n√©ration des donn√©es** : Donn√©es des patients avec leurs param√®tres vitaux.
2. **Ingestion des donn√©es** dans Kafka.
3. **Traitement des donn√©es** en trois √©tapes successives :
   - Extraction du nom et pr√©nom.
   - Formatage de la date (timestamp).
   - Classification de la pression art√©rielle en fonction de la pression et de l'√¢ge.
4. **Stockage des donn√©es dans Redis** sous forme de liste avec la cl√© **"liste-patients"**.
5. **Visualisation des donn√©es avec Grafana** pour l'analyse des param√®tres vitaux stock√©s dans Redis.

## D√©ploiement de la solution


### **Pr√©requis**

Avant de lancer le projet, assurez-vous d‚Äôavoir install√© :

- **Docker**
- **Python 3.x**
- **Grafana** (optionnel)

### **√âtapes de Lancement du projet**

1. **Cloner le repository**

   ```bash
   git clone https://github.com/votre-repository.git
   cd votre-repository
   ```

2. **Initialiser l'environnement**\
   Pour initialiser l'environnement, ex√©cutez la commande suivante :

   ```bash
   docker-compose up airflow-init
   ```

3. **D√©marrer l'ex√©cution d'Airflow**\
   Vous pouvez d√©marrer l'ex√©cution d'Airflow en ex√©cutant la commande :

   ```bash
   docker-compose up -d
   ```

   Vous pouvez v√©rifier que le conteneur fonctionne en ex√©cutant la commande :

   ```bash
   docker ps
   ```

   > **Remarque :** Dans votre dossier `votre-repository`, vous devriez trouver les fichiers et dossiers suivants :

   ![Structure du dossier](images/structure_dossir_airflow.PNG)

4. **Acc√®s √† l'interface Web Airflow**\
   Connectez-vous √† l'interface Web et essayez d'ex√©cuter certaines t√¢ches.

   - üìå Le serveur Web est disponible √† l'adresse : [**http://localhost:8080**](http://localhost:8080)
   - üîë Utilisez le compte par d√©faut :
     - **Utilisateur** : `airflow`
     - **Mot de passe** : `airflow`

5. **Ex√©cution du DAG de notre solution**

   5.1 **Ajouter le fichier DAG**\
   Placez le fichier `dag_ingestion.py` dans le r√©pertoire `votre-repository/dags` :

   ```bash
   mv dag_ingestion.py dags
   ```

   5.2 **Activer le DAG**

   - Dans l'interface Web Airflow, rep√©rez le DAG avec l'identifiant **a\_kafka\_redis\_airflow**
   - Activez-le en cliquant sur le bouton d‚Äôactivation

   5.3 **Explorer le DAG**

   - ‚úÖ Visualiser le **sch√©ma du DAG**
   - ‚úÖ V√©rifier le **diagramme de Gantt**
   - ‚úÖ Consulter les **logs de chaque t√¢che**
   - ‚úÖ D√©boguer en cas d‚Äôerreur

## **Acc√®s aux donn√©es stock√©es dans Redis**

Apr√®s l‚Äôex√©cution du pipeline, vous pouvez v√©rifier que les donn√©es des patients ont bien √©t√© enregistr√©es dans Redis :

1. Acc√©dez au conteneur Redis :
   ```bash
   docker exec -it redis redis-cli
   ```
2. Consultez la liste des patients stock√©e :
   ```bash
   LRANGE liste-patients 0 -1
   ```

## **Visualisation des donn√©es avec Grafana**(Optionel)

Grafana est utilis√© pour analyser et visualiser les donn√©es stock√©es dans Redis.

### **1. Acc√®s √† Grafana**

L‚Äôinterface Web de Grafana est disponible √† l'adresse suivante :

üîó [**http://localhost:3001**](http://localhost:3001)

Utilisez les identifiants par d√©faut :

- **Utilisateur** : `admin`
- **Mot de passe** : `admin` (modifiable apr√®s la premi√®re connexion).

### **2. Configuration de Redis comme source de donn√©es**

- Dans Grafana, acc√©dez √† **Configuration > Data Sources**.
- Ajoutez une nouvelle source de donn√©es et s√©lectionnez **Redis**.
- Configurez la connexion en pr√©cisant l‚Äôadresse du conteneur Redis et le port **6379**.
- Sauvegardez et testez la connexion.

### **3. Cr√©ation d'un tableau de bord**

- Ajoutez un **nouveau tableau de bord**.
- Configurez des graphiques pour afficher les param√®tres vitaux des patients.
- Personnalisez l'affichage selon les besoins d'analyse.
- ...

## R√©sultats obtenus


---
